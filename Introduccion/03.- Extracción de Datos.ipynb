{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#000047; padding: 30px; border-radius: 10px; color: white; text-align: center;\">\n",
    "    <img src='Figures/alinco.png' style=\"height: 100px; margin-bottom: 10px;\"/>\n",
    "    <h1>Extracci√≥n de Datos de Diferentes Fuentes</h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La **extracci√≥n de datos** es el proceso de obtener informaci√≥n relevante desde diversas fuentes y formatos, como archivos de texto, hojas de c√°lculo, bases de datos, im√°genes, archivos web, APIs, entre otros. En la actualidad, los datos se encuentran dispersos y almacenados en m√∫ltiples formas, por lo que saber c√≥mo acceder, limpiar y transformar estos datos es una habilidad fundamental.\n",
    "\n",
    "#### ¬øPor qu√© es importante la extracci√≥n de datos?\n",
    "\n",
    "- Permite **integrar informaci√≥n** de diferentes sistemas y plataformas.\n",
    "- Es el primer paso para el **an√°lisis de datos** y la toma de decisiones basada en evidencia.\n",
    "- Facilita la **automatizaci√≥n** de procesos y la actualizaci√≥n constante de informaci√≥n.\n",
    "- Es esencial para la **preparaci√≥n de datos** en proyectos de ciencia de datos e inteligencia artificial.\n",
    "\n",
    "En proyectos de **Inteligencia Artificial (IA)**, la calidad y diversidad de los datos es clave para entrenar modelos robustos y precisos. La extracci√≥n de datos permite:\n",
    "\n",
    "- **Construir datasets** a partir de fuentes reales y actualizadas.\n",
    "- **Preprocesar y limpiar** la informaci√≥n antes de alimentar algoritmos de machine learning.\n",
    "- **Enriquecer modelos** combinando datos estructurados (tablas, bases de datos) y no estructurados (texto, im√°genes, audio).\n",
    "- **Automatizar la recolecci√≥n** de datos para sistemas de IA en producci√≥n.\n",
    "\n",
    "Dominar las t√©cnicas de extracci√≥n de datos te permitir√° abordar problemas complejos, crear soluciones inteligentes y aprovechar el potencial de la IA en cualquier √°rea profesional."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#e6f2ff; border-left:4px solid #000047; padding:10px;\">\n",
    "En este notebook aprender√°s a extraer datos desde archivos CSV, Excel, texto, JSON, XML, im√°genes, HTML y SHP, utilizando Python y sus principales librer√≠as.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargar archivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Almacenamos la ruta de los archivos en una variable\n",
    "ruta='Data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Archivos Excel y CSV\n",
    "\n",
    "Los archivos Excel (`.xlsx`, `.xls`) y CSV (`.csv`) son formatos tabulares ampliamente utilizados para almacenar datos estructurados. Python, a trav√©s de la librer√≠a `pandas`, permite leer y manipular estos archivos de manera sencilla y eficiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contenido del archivo CSV:\n",
      "   Unnamed: 0        country  rank  year   gdppc\n",
      "0           0  Liechtenstein     1  2008  141100\n",
      "1           1      Singapore     4  2011   59900\n",
      "2           2         Panama    68  2011   13600\n"
     ]
    }
   ],
   "source": [
    "df_csv = pd.read_csv(ruta+'df_tabla2.csv')\n",
    "print('Contenido del archivo CSV:')\n",
    "print(df_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Archivos de texto\n",
    "### De texto a `DataFrame`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pd.read_fwf` de pandas se utiliza para leer archivos de texto con columnas de ancho fijo (fixed-width formatted lines) y cargarlos en un DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ana</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Beto</td>\n",
       "      <td>1.1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alfredo</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Armando</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0    1   2\n",
       "0      Ana  1.0  10\n",
       "1     Beto  1.1  10\n",
       "2  Alfredo  6.0   9\n",
       "3  Armando  5.0   9"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extracci√≥n a partir de texto separado por tabular\n",
    "pd.read_fwf(ruta+'texto_2.txt',header=None) # No se puede especificar el separador"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`read_table` de pandas se utiliza para leer archivos de texto delimitados (por defecto, separados por tabulaciones) y cargarlos en un DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ana</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Beto</td>\n",
       "      <td>1.1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alfredo</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Armando</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0    1   2\n",
       "0  Ana       1.0  10\n",
       "1  Beto      1.1  10\n",
       "2  Alfredo   6.0   9\n",
       "3  Armando   5.0   9"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_table(ruta+'texto_2.txt',header=None) # sep='\\t'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ana</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Beto</td>\n",
       "      <td>1.1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alfredo</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Armando</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0    1   2\n",
       "0      Ana  1.0  10\n",
       "1     Beto  1.1  10\n",
       "2  Alfredo  6.0   9\n",
       "3  Armando  5.0   9"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extracci√≥n a partir de texto separado por comas\n",
    "pd.read_table(ruta+'texto_1.txt',sep=',',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ana,</td>\n",
       "      <td>1,</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Beto,</td>\n",
       "      <td>1.1,</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alfredo,</td>\n",
       "      <td>6,</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Armando,</td>\n",
       "      <td>5,</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0     1   2\n",
       "0      Ana,    1,  10\n",
       "1     Beto,  1.1,  10\n",
       "2  Alfredo,    6,   9\n",
       "3  Armando,    5,   9"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_table(ruta+'texto_1.txt',sep=' ',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ana</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Beto</td>\n",
       "      <td>1.1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alfredo</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Armando</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0    1   2\n",
       "0  Ana       1.0  10\n",
       "1  Beto      1.1  10\n",
       "2  Alfredo   6.0   9\n",
       "3  Armando   5.0   9"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(ruta+'texto_2.txt',header=None,sep='\\t') # sep=','"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversi√≥n de archivo a variable\n",
    "file=open(ruta+'texto_3.txt')     # Abrir...\n",
    "texto=file.read()\n",
    "file.close()                      # ...despues cerrar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'En un lugar de la Mancha, de cuyo nombre no quiero acordarme, no ha mucho tiempo que viv√É\\xada un hidalgo de los de lanza en astillero, adarga antigua, roc√É¬≥n flaco y galgo corredor. Una olla de algo m√É¬°s vaca que carnero, salpic√É¬≥n las m√É¬°s noches, duelos y quebrantos los s√É¬°bados, lantejas los viernes, alg√É¬∫n palomino de a√É¬±adidura los domingos, consum√É\\xadan las tres partes de su hacienda. El resto della conclu√É\\xadan sayo de velarte, calzas de velludo para las fiestas, con sus pantuflos de lo mesmo, y los d√É\\xadas de entresemana se honraba con su vellor√É\\xad de lo m√É¬°s fino. Ten√É\\xada en su casa una ama que pasaba de los cuarenta, y una sobrina que no llegaba a los veinte, y un mozo de campo y plaza, que as√É\\xad ensillaba el roc√É\\xadn como tomaba la podadera. Frisaba la edad de nuestro hidalgo con los cincuenta a√É¬±os; era de complexi√É¬≥n recia, seco de carnes, enjuto de rostro, gran madrugador y amigo de la caza. Quieren decir que ten√É\\xada el sobrenombre de Quijada, o Quesada, que en esto hay alguna diferencia en los autores que deste caso escriben; aunque por conjeturas veros√É\\xadmiles se deja entender que se llamaba Quijana. Pero esto importa poco a nuestro cuento: basta que en la narraci√É¬≥n d√É¬©l no se salga un punto de la verdad.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Si ocurre un error durante la ejecuci√≥n, la variable file se cierra siempre:\n",
    "with open(ruta+'texto_3.txt') as file:\n",
    "  texto=file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'En un lugar de la Mancha, de cuyo nombre no quiero acordarme, no ha mucho tiempo que viv√É\\xada un hidalgo de los de lanza en astillero, adarga antigua, roc√É¬≥n flaco y galgo corredor. Una olla de algo m√É¬°s vaca que carnero, salpic√É¬≥n las m√É¬°s noches, duelos y quebrantos los s√É¬°bados, lantejas los viernes, alg√É¬∫n palomino de a√É¬±adidura los domingos, consum√É\\xadan las tres partes de su hacienda. El resto della conclu√É\\xadan sayo de velarte, calzas de velludo para las fiestas, con sus pantuflos de lo mesmo, y los d√É\\xadas de entresemana se honraba con su vellor√É\\xad de lo m√É¬°s fino. Ten√É\\xada en su casa una ama que pasaba de los cuarenta, y una sobrina que no llegaba a los veinte, y un mozo de campo y plaza, que as√É\\xad ensillaba el roc√É\\xadn como tomaba la podadera. Frisaba la edad de nuestro hidalgo con los cincuenta a√É¬±os; era de complexi√É¬≥n recia, seco de carnes, enjuto de rostro, gran madrugador y amigo de la caza. Quieren decir que ten√É\\xada el sobrenombre de Quijada, o Quesada, que en esto hay alguna diferencia en los autores que deste caso escriben; aunque por conjeturas veros√É\\xadmiles se deja entender que se llamaba Quijana. Pero esto importa poco a nuestro cuento: basta que en la narraci√É¬≥n d√É¬©l no se salga un punto de la verdad.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['En',\n",
       " 'un',\n",
       " 'lugar',\n",
       " 'de',\n",
       " 'la',\n",
       " 'Mancha,',\n",
       " 'de',\n",
       " 'cuyo',\n",
       " 'nombre',\n",
       " 'no',\n",
       " 'quiero',\n",
       " 'acordarme,',\n",
       " 'no',\n",
       " 'ha',\n",
       " 'mucho',\n",
       " 'tiempo',\n",
       " 'que',\n",
       " 'viv√É\\xada',\n",
       " 'un',\n",
       " 'hidalgo',\n",
       " 'de',\n",
       " 'los',\n",
       " 'de',\n",
       " 'lanza',\n",
       " 'en',\n",
       " 'astillero,',\n",
       " 'adarga',\n",
       " 'antigua,',\n",
       " 'roc√É¬≥n',\n",
       " 'flaco',\n",
       " 'y',\n",
       " 'galgo',\n",
       " 'corredor.',\n",
       " 'Una',\n",
       " 'olla',\n",
       " 'de',\n",
       " 'algo',\n",
       " 'm√É¬°s',\n",
       " 'vaca',\n",
       " 'que',\n",
       " 'carnero,',\n",
       " 'salpic√É¬≥n',\n",
       " 'las',\n",
       " 'm√É¬°s',\n",
       " 'noches,',\n",
       " 'duelos',\n",
       " 'y',\n",
       " 'quebrantos',\n",
       " 'los',\n",
       " 's√É¬°bados,',\n",
       " 'lantejas',\n",
       " 'los',\n",
       " 'viernes,',\n",
       " 'alg√É¬∫n',\n",
       " 'palomino',\n",
       " 'de',\n",
       " 'a√É¬±adidura',\n",
       " 'los',\n",
       " 'domingos,',\n",
       " 'consum√É\\xadan',\n",
       " 'las',\n",
       " 'tres',\n",
       " 'partes',\n",
       " 'de',\n",
       " 'su',\n",
       " 'hacienda.',\n",
       " 'El',\n",
       " 'resto',\n",
       " 'della',\n",
       " 'conclu√É\\xadan',\n",
       " 'sayo',\n",
       " 'de',\n",
       " 'velarte,',\n",
       " 'calzas',\n",
       " 'de',\n",
       " 'velludo',\n",
       " 'para',\n",
       " 'las',\n",
       " 'fiestas,',\n",
       " 'con',\n",
       " 'sus',\n",
       " 'pantuflos',\n",
       " 'de',\n",
       " 'lo',\n",
       " 'mesmo,',\n",
       " 'y',\n",
       " 'los',\n",
       " 'd√É\\xadas',\n",
       " 'de',\n",
       " 'entresemana',\n",
       " 'se',\n",
       " 'honraba',\n",
       " 'con',\n",
       " 'su',\n",
       " 'vellor√É\\xad',\n",
       " 'de',\n",
       " 'lo',\n",
       " 'm√É¬°s',\n",
       " 'fino.',\n",
       " 'Ten√É\\xada',\n",
       " 'en',\n",
       " 'su',\n",
       " 'casa',\n",
       " 'una',\n",
       " 'ama',\n",
       " 'que',\n",
       " 'pasaba',\n",
       " 'de',\n",
       " 'los',\n",
       " 'cuarenta,',\n",
       " 'y',\n",
       " 'una',\n",
       " 'sobrina',\n",
       " 'que',\n",
       " 'no',\n",
       " 'llegaba',\n",
       " 'a',\n",
       " 'los',\n",
       " 'veinte,',\n",
       " 'y',\n",
       " 'un',\n",
       " 'mozo',\n",
       " 'de',\n",
       " 'campo',\n",
       " 'y',\n",
       " 'plaza,',\n",
       " 'que',\n",
       " 'as√É\\xad',\n",
       " 'ensillaba',\n",
       " 'el',\n",
       " 'roc√É\\xadn',\n",
       " 'como',\n",
       " 'tomaba',\n",
       " 'la',\n",
       " 'podadera.',\n",
       " 'Frisaba',\n",
       " 'la',\n",
       " 'edad',\n",
       " 'de',\n",
       " 'nuestro',\n",
       " 'hidalgo',\n",
       " 'con',\n",
       " 'los',\n",
       " 'cincuenta',\n",
       " 'a√É¬±os;',\n",
       " 'era',\n",
       " 'de',\n",
       " 'complexi√É¬≥n',\n",
       " 'recia,',\n",
       " 'seco',\n",
       " 'de',\n",
       " 'carnes,',\n",
       " 'enjuto',\n",
       " 'de',\n",
       " 'rostro,',\n",
       " 'gran',\n",
       " 'madrugador',\n",
       " 'y',\n",
       " 'amigo',\n",
       " 'de',\n",
       " 'la',\n",
       " 'caza.',\n",
       " 'Quieren',\n",
       " 'decir',\n",
       " 'que',\n",
       " 'ten√É\\xada',\n",
       " 'el',\n",
       " 'sobrenombre',\n",
       " 'de',\n",
       " 'Quijada,',\n",
       " 'o',\n",
       " 'Quesada,',\n",
       " 'que',\n",
       " 'en',\n",
       " 'esto',\n",
       " 'hay',\n",
       " 'alguna',\n",
       " 'diferencia',\n",
       " 'en',\n",
       " 'los',\n",
       " 'autores',\n",
       " 'que',\n",
       " 'deste',\n",
       " 'caso',\n",
       " 'escriben;',\n",
       " 'aunque',\n",
       " 'por',\n",
       " 'conjeturas',\n",
       " 'veros√É\\xadmiles',\n",
       " 'se',\n",
       " 'deja',\n",
       " 'entender',\n",
       " 'que',\n",
       " 'se',\n",
       " 'llamaba',\n",
       " 'Quijana.',\n",
       " 'Pero',\n",
       " 'esto',\n",
       " 'importa',\n",
       " 'poco',\n",
       " 'a',\n",
       " 'nuestro',\n",
       " 'cuento:',\n",
       " 'basta',\n",
       " 'que',\n",
       " 'en',\n",
       " 'la',\n",
       " 'narraci√É¬≥n',\n",
       " 'd√É¬©l',\n",
       " 'no',\n",
       " 'se',\n",
       " 'salga',\n",
       " 'un',\n",
       " 'punto',\n",
       " 'de',\n",
       " 'la',\n",
       " 'verdad.']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separamos cada palabra de la variable de texto\n",
    "texto.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mSignature:\u001b[0m \u001b[0mtexto\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmaxsplit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m\n",
       "Return a list of the substrings in the string, using sep as the separator string.\n",
       "\n",
       "  sep\n",
       "    The separator used to split the string.\n",
       "\n",
       "    When set to None (the default value), will split on any whitespace\n",
       "    character (including \\n \\r \\t \\f and spaces) and will discard\n",
       "    empty strings from the result.\n",
       "  maxsplit\n",
       "    Maximum number of splits.\n",
       "    -1 (the default value) means no limit.\n",
       "\n",
       "Splitting starts at the front of the string and works to the end.\n",
       "\n",
       "Note, str.split() is mainly useful for data that has been intentionally\n",
       "delimited.  With natural text that includes punctuation, consider using\n",
       "the regular expression module.\n",
       "\u001b[1;31mType:\u001b[0m      builtin_function_or_method"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "texto.split?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expresiones regulares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las <b>expresiones regulares</b> son patrones que permiten buscar, extraer, validar y manipular texto de manera flexible y eficiente. Son esenciales para limpiar datos, extraer informaci√≥n y validar formatos en archivos de texto.\n",
    "\n",
    "### Caracteres y operadores b√°sicos\n",
    "\n",
    "| S√≠mbolo | Significado | Ejemplo |\n",
    "|---------|-------------|---------|\n",
    "| `.`     | Cualquier car√°cter | `a.b` encuentra 'acb', 'aab', etc. |\n",
    "| `\\d`   | D√≠gito (0-9) | `\\d\\d` encuentra dos d√≠gitos |\n",
    "| `\\w`   | Car√°cter alfanum√©rico | `\\w+` encuentra palabras |\n",
    "| `\\s`   | Espacio en blanco | `\\s+` encuentra espacios |\n",
    "| `*`     | Cero o m√°s repeticiones | `ab*` encuentra 'a', 'ab', 'abb', ... |\n",
    "| `+`     | Una o m√°s repeticiones | `ab+` encuentra 'ab', 'abb', ... |\n",
    "| `?`     | Cero o una repetici√≥n | `ab?` encuentra 'a', 'ab' |\n",
    "| `^`     | Inicio de l√≠nea | `^Hola` encuentra l√≠neas que empiezan con 'Hola' |\n",
    "| `$`     | Fin de l√≠nea | `mundo$` encuentra l√≠neas que terminan con 'mundo' |\n",
    "| `[abc]` | Cualquier car√°cter a, b o c | `[aeiou]` encuentra vocales |\n",
    "| `( )`   | Agrupaci√≥n | `(abc)+` encuentra 'abc', 'abcabc', ... |\n",
    "\n",
    "### Funciones principales en Python (`re`)\n",
    "\n",
    "- `re.search(patron, texto)`: Busca el patr√≥n en el texto y devuelve el primer resultado.\n",
    "- `re.match(patron, texto)`: Verifica si el patr√≥n coincide al inicio del texto.\n",
    "- `re.findall(patron, texto)`: Devuelve todas las coincidencias del patr√≥n.\n",
    "- `re.sub(patron, reemplazo, texto)`: Reemplaza coincidencias por otro texto.\n",
    "\n",
    "### Ejemplo: Buscar correos electr√≥nicos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "texto_correo = \"Mi correo es gdesirena@outlook.mx pero anteriormente usaba gdesirena@gmail.com, gaddiel.desirena.lopez@alinco.mx\"\n",
    "patron = r\"\\w+@\\w+\\.\\w+\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gdesirena@outlook.mx', 'gdesirena@gmail.com', 'lopez@alinco.mx']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(patron, texto_correo) #Devuelve todas las coincidencias del patron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "texto_correo = \"Mi correo es gdesirena@outlook.mx pero anteriormente usaba gdesirena@gmail.com, gaddiel.desirena.lopez@alinco.mx\"\n",
    "patron = r\"\\w+@\\[w+\\.]\\w+\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo: Extraer dominios de correos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dominios encontrados: ['outlook.mx', 'gmail.com', 'alinco.mx']\n"
     ]
    }
   ],
   "source": [
    "dominios = re.findall(r'@([\\w\\.-]+)', texto_correo)\n",
    "print('Dominios encontrados:', dominios)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo: Buscar fechas en formato DD/MM/AAAA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fechas encontradas: ['15/09/2023', '01/01/2024']\n"
     ]
    }
   ],
   "source": [
    "texto_fechas = 'algunas fechas importantes son 15/09/2023 y 01/01/2024.' \n",
    "fechas = re.findall(r'\\b\\d{2}/\\d{2}/\\d{4}\\b', texto_fechas)\n",
    "print('Fechas encontradas:', fechas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo: Validar n√∫meros de tel√©fono\n",
    "\n",
    "Busca n√∫meros en formato internacional (+52 33 1234 5678):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tel√©fonos encontrados: ['+52 33 1234 5678', '+52 55 8765 4321']\n"
     ]
    }
   ],
   "source": [
    "texto_tel = 'Mi n√∫mero es +52 33 1234 5678 y el de mi amigo es +52 55 8765 4321.'\n",
    "patron_tel = r'\\+\\d{2}\\s\\d{2}\\s\\d{4}\\s\\d{4}'\n",
    "telefonos = re.findall(patron_tel, texto_tel)\n",
    "print('Tel√©fonos encontrados:', telefonos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo: Reemplazo de texto\n",
    "\n",
    "Reemplaza todos los d√≠gitos por 'X':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mi clave es XXXX y mi usuario es userXX.\n"
     ]
    }
   ],
   "source": [
    "texto = 'Mi clave es 1234 y mi usuario es user01.'\n",
    "nuevo_texto = re.sub(r'\\d', 'X', texto)\n",
    "print(nuevo_texto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo: Conteo de palabras usando regex\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = re.split(r'\\W', texto)\n",
    "S = set(L)\n",
    "S.discard('')\n",
    "d = {}\n",
    "for palabra in S:\n",
    "    d[palabra] = len(re.findall(palabra, texto, flags=re.I))\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 1\n",
    "\n",
    "Busca todas las palabras que empiezan con la letra 'u' en el texto anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tu c√≥digo aqu√≠"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 2\n",
    "\n",
    "Extrae todos los n√∫meros de una cadena de texto y convi√©rtelos a enteros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tu c√≥digo aqu√≠"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recursos √∫tiles\n",
    "\n",
    "- [regex101.com](https://regex101.com/) - expresiones regulares en l√≠nea.\n",
    "- [Documentaci√≥n oficial de re](https://docs.python.org/3/library/re.html)\n",
    "\n",
    "<div style=\"background-color:#e6f2ff; border-left:4px solid #000047; padding:10px;\">\n",
    "Las expresiones regulares son una herramienta poderosa para la limpieza y extracci√≥n de datos en proyectos de IA y ciencia de datos.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Archivos excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A partir de la funci√≥n\n",
    "pd.read_excel(ruta+'API_SI.POV.DDAY_DS2_en_excel_v2_1930012.xls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos la clase ExcelFile\n",
    "from pandas import ExcelFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A partir de la clase\n",
    "obj=ExcelFile(ruta+'API_SI.POV.DDAY_DS2_en_excel_v2_1930012.xls')\n",
    "obj.parse() # Importa la primera p√°gina"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Archivos JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El formato JSON (JavaScript Object Notation) es ampliamente utilizado para el intercambio de datos, especialmente en aplicaciones web y APIs. Python incluye la librer√≠a est√°ndar `json` para leer y manipular archivos JSON."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "json_data = '{\"personas\": [{\"nombre\": \"Ana\", \"edad\": 23}, {\"nombre\": \"Luis\", \"edad\": 31}]}'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import json_normalize\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_json['categories'][0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Archivos XML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El formato XML es com√∫n para el intercambio de datos estructurados. Python ofrece la librer√≠a est√°ndar `xml.etree.ElementTree` para analizar y extraer informaci√≥n de archivos XML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "xml_data = '''\n",
    "<personas>\n",
    "  <persona>\n",
    "    <nombre>Ana</nombre>\n",
    "    <edad>23</edad>\n",
    "  </persona>\n",
    "  <persona>\n",
    "    <nombre>Luis</nombre>\n",
    "    <edad>31</edad>\n",
    "  </persona>\n",
    "</personas>\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Personas extra√≠das del archivo XML:\n",
      "Nombre: Ana, Edad: 23\n",
      "Nombre: Luis, Edad: 31\n"
     ]
    }
   ],
   "source": [
    "\n",
    "root = ET.fromstring(xml_data)\n",
    "print('Personas extra√≠das del archivo XML:')\n",
    "for persona in root.findall('persona'):\n",
    "    nombre = persona.find('nombre').text\n",
    "    edad = persona.find('edad').text\n",
    "    print(f'Nombre: {nombre}, Edad: {edad}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Ejemplo con tabla_1.xml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archivo_1=ET.parse(ruta+'tabla_1.xml')\n",
    "raiz=archivo_1.getroot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raiz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for nodo in raiz:\n",
    "    print(nodo.attrib,nodo.text,nodo.tag)\n",
    "    for sn in nodo:\n",
    "        print(sn.attrib,sn.text,sn.tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archivo_2=ET.parse(ruta+'tabla_2.xml')\n",
    "root=archivo_2.getroot()\n",
    "for nodo in root:\n",
    "    print(nodo.tag,nodo.attrib,nodo.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for nodo in root:\n",
    "    for subn in nodo:\n",
    "        print(subn.tag,subn.attrib,subn.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extraer los datos de tabla_1.xml\n",
    "d={}\n",
    "for nodo in raiz:\n",
    "    d[nodo.tag]=[]\n",
    "for nodo in raiz:\n",
    "    d[nodo.tag].append(nodo.attrib['name'])\n",
    "for nodo in raiz:\n",
    "    for sn in nodo:\n",
    "        d[sn.tag]=[]\n",
    "for nodo in raiz:\n",
    "    for sn in nodo:\n",
    "        d[sn.tag].append(sn.text)\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "df_1 = pd.DataFrame(columns = columnas)\n",
    "for nodo in raiz:\n",
    "  L = []\n",
    "  L.append(nodo.attrib['name'])\n",
    "  for sn in nodo:\n",
    "    L.append(sn.text)\n",
    "  df_1 = df_1.append(pd.DataFrame([L], columns=columnas), ignore_index=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archivo=ET.parse(ruta+'tabla_2.xml')\n",
    "raiz=archivo.getroot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L=[]\n",
    "for n in raiz.findall('documents/document'):\n",
    "    d={}\n",
    "    d[n.tag]=n.text\n",
    "    for k,v in n.attrib.items():\n",
    "        d[k]=v\n",
    "    L.append(d)\n",
    "pd.DataFrame(L)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archivo='IFC-Subscriptions-and-Voting-Power-of-Member-Count.xml'\n",
    "file=ET.parse(ruta+archivo)\n",
    "root=file.getroot()\n",
    "\n",
    "for nodo in root:\n",
    "    for snodo in nodo:\n",
    "        print(snodo.tag,snodo.attrib,snodo.text)\n",
    "        for ssnodo in snodo:\n",
    "            print(ssnodo.tag,ssnodo.attrib,ssnodo.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Archivos SHP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los archivos Shapefile (`.shp`) son un formato est√°ndar para almacenar informaci√≥n geoespacial vectorial. La librer√≠a `geopandas` permite leer y manipular estos archivos de manera sencilla. Un Shapefile suele estar acompa√±ado de otros archivos como `.shx` y `.dbf`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install geopandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install geopandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %conda !pip !conda\n",
    "%pip install geopandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_df = gpd.read_file('COVID_INDIA_POC-shp/COVID_INDIA_POC.shp')\n",
    "g_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "g_df.plot(\n",
    "    ax=ax,\n",
    "    column=g_df.columns[0],  # Cambia por la columna que quieras destacar\n",
    "    cmap='viridis',\n",
    "    edgecolor='black',\n",
    "    legend=True\n",
    ")\n",
    "ax.set_title('COVID_INDIA_POC', fontsize=12)\n",
    "ax.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Archivos HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leer un archivo HTML local\n",
    "with open(ruta+'ejemplo.html', 'r', encoding='utf-8') as file:\n",
    "    html_content = file.read()\n",
    "print(html_content[:500])  # Muestra los primeros 500 caracteres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install beautifulsoup4 #Instalar BeautifulSoup si es necesario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analizar HTML con BeautifulSoup\n",
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "# Extraer el t√≠tulo de la p√°gina\n",
    "titulo = soup.title.string\n",
    "print('T√≠tulo de la p√°gina:', titulo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraer los enlaces de la p√°gina\n",
    "enlaces = soup.find_all('a')\n",
    "for enlace in enlaces:\n",
    "    print(enlace.get('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install requests # Instalar requests si es necesario\n",
    "import requests\n",
    "\n",
    "url = 'https://www.python.org/'\n",
    "response = requests.get(url)\n",
    "web_html = response.text\n",
    "\n",
    "# Analizar el HTML descargado\n",
    "soup_web = BeautifulSoup(web_html, 'html.parser')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(soup_web.title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Ejemplo sencillo webscraping "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    " \n",
    "url = \"https://codedamn-classrooms.github.io/webscraper-python-codedamn-classroom-website/\"\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "type(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtener un dataframe con la informaci√≥n de los productos\n",
    "products = []\n",
    "\n",
    "for price_tag in soup.find_all(\"h4\", string=lambda s: s and s.strip().startswith(\"$\")):\n",
    "    # El nombre del producto es la cadena que sigue despu√©s del tag <a> despu√©s del precio\n",
    "    product_link = price_tag.find_next(\"a\")\n",
    "    if not product_link:\n",
    "        continue\n",
    "    product_name = product_link.text.strip()\n",
    "    product_url = product_link[\"href\"]\n",
    "    # La descripci√≥n es el siguien tag <p> despu√©s de la liga del producto\n",
    "    description_tag = product_link.find_next(\"p\")\n",
    "    description = description_tag.text.strip() if description_tag else \"\"\n",
    "    # Los numero de reviews van despu√©s de <div> \n",
    "    reviews_tag = product_link.find_next(string=lambda s: s and \"review\" in s)\n",
    "    try:\n",
    "        reviews = int(reviews_tag.strip().split()[0])\n",
    "    except Exception:\n",
    "        reviews = None\n",
    "    # Precio\n",
    "    try:\n",
    "        price = float(price_tag.text.strip().replace(\"$\", \"\"))\n",
    "    except Exception:\n",
    "        price = None\n",
    " \n",
    "    products.append({\n",
    "        \"Product Name\": product_name,\n",
    "        \"Price\": price,\n",
    "        \"Description\": description,\n",
    "        \"Reviews\": reviews,\n",
    "        \"Product URL\": product_url\n",
    "    })\n",
    " \n",
    "df = pd.DataFrame(products)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Archivos im√°gen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las im√°genes RGB almacenan informaci√≥n de color en tres canales: Rojo (R), Verde (G) y Azul (B). Para leer y manipular im√°genes en Python, se pueden usar las librer√≠as `Pillow` (PIL), `matplotlib` y `numpy`. Esto permite acceder a los valores de los p√≠xeles y realizar an√°lisis o transformaciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I=plt.imread(ruta+'imagen.bmp')\n",
    "I.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I[0,0,0] # pixel (0,0) de la matriz roja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(I[:,:,0],cmap='gray') # Matriz roja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G=I.mean(axis=2)\n",
    "G.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G[0,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplos de aplicaciones en IA para cada tipo de archivo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîé Ejemplos de aplicaciones en IA para cada tipo de archivo\n",
    "\n",
    "### üìÑ Archivos de texto:\n",
    "\n",
    "- **An√°lisis de sentimientos:** Procesar opiniones de usuarios para determinar si son positivas o negativas.\n",
    "- **Extracci√≥n de palabras clave:** Identificar t√©rminos importantes en grandes vol√∫menes de texto.\n",
    "- **Procesamiento de lenguaje natural (NLP):** Tokenizaci√≥n, lematizaci√≥n y an√°lisis de frecuencia de palabras.\n",
    "- **An√°lisis de logs:** Detectar patrones o anomal√≠as en archivos de registro.\n",
    "- **Generaci√≥n autom√°tica de res√∫menes:** Resumir textos extensos con modelos de IA.\n",
    "- **Reconocimiento de entidades:** Extraer nombres de personas, lugares y organizaciones.\n",
    "- **Clasificaci√≥n de documentos:** Categorizar textos en temas o g√©neros.\n",
    "- **Traducci√≥n autom√°tica:** Convertir textos entre idiomas usando IA.\n",
    "\n",
    "### üìä Archivos Excel y CSV:\n",
    "\n",
    "- **An√°lisis exploratorio de datos (EDA):** Calcular totales, medias y tendencias.\n",
    "- **Preparaci√≥n de datos para ML:** Ingenier√≠a de caracter√≠sticas y limpieza de datos.\n",
    "- **Reportes automatizados:** Generar res√∫menes y exportar resultados.\n",
    "- **Detecci√≥n de anomal√≠as:** Identificar valores at√≠picos.\n",
    "- **Predicci√≥n de tendencias:** Series temporales para prever ventas.\n",
    "- **Segmentaci√≥n de clientes:** Agrupar clientes por patrones de compra.\n",
    "- **Visualizaci√≥n de datos:** Dashboards interactivos y gr√°ficos.\n",
    "\n",
    "### üñºÔ∏è Archivos de im√°genes RGB:\n",
    "\n",
    "- **Visi√≥n por computadora:** Clasificaci√≥n de im√°genes y reconocimiento facial.\n",
    "- **Procesamiento de im√°genes m√©dicas:** Detecci√≥n de regiones an√≥malas.\n",
    "- **Extracci√≥n de caracter√≠sticas visuales:** Histogramas y patrones de color.\n",
    "- **Detecci√≥n de objetos:** Localizaci√≥n y clasificaci√≥n en im√°genes.\n",
    "- **Reconstrucci√≥n 3D:** Modelos tridimensionales a partir de im√°genes.\n",
    "- **Segmentaci√≥n sem√°ntica:** Delimitaci√≥n de regiones espec√≠ficas.\n",
    "- **Realidad aumentada:** Superposici√≥n de informaci√≥n digital.\n",
    "\n",
    "### üóÇÔ∏è Archivos XML:\n",
    "\n",
    "- **Integraci√≥n de datos empresariales:** Extraer informaci√≥n de sistemas ERP.\n",
    "- **Procesamiento de datos IoT:** Leer registros de sensores.\n",
    "- **An√°lisis de publicaciones cient√≠ficas:** Obtener t√≠tulos y autores.\n",
    "- **Intercambio de datos entre aplicaciones:** Estandarizaci√≥n e interoperabilidad.\n",
    "- **Validaci√≥n de esquemas:** Verificar estructura y consistencia.\n",
    "- **Extracci√≥n de datos jer√°rquicos:** Navegaci√≥n en √°rboles complejos.\n",
    "- **Automatizaci√≥n de reportes:** Generar informes estructurados.\n",
    "\n",
    "### { } Archivos JSON:\n",
    "\n",
    "- **Consumo de APIs web:** Obtener y analizar datos en tiempo real.\n",
    "- **Almacenamiento y an√°lisis de logs:** Procesar registros de aplicaciones.\n",
    "- **An√°lisis de datos m√≥viles:** Leer resultados de encuestas y m√©tricas.\n",
    "- **Integraci√≥n de datos en tiempo real:** Sensores y dispositivos conectados.\n",
    "- **Visualizaci√≥n de datos:** Gr√°ficos y mapas interactivos.\n",
    "- **Entrenamiento de modelos de IA:** Datasets estructurados para algoritmos.\n",
    "- **Validaci√≥n y limpieza de datos:** Correcci√≥n de inconsistencias.\n",
    "\n",
    "### üó∫Ô∏è Archivos Shapefile (SHP):\n",
    "\n",
    "- **An√°lisis geoespacial:** Distancias y relaciones espaciales.\n",
    "- **Estudios ambientales y urbanos:** Distribuci√≥n de √°reas verdes y zonas urbanas.\n",
    "- **Modelado de redes y transporte:** Rutas √≥ptimas y predicci√≥n de tr√°fico.\n",
    "- **An√°lisis de riesgos naturales:** Identificaci√≥n de zonas vulnerables.\n",
    "- **Visualizaci√≥n de mapas tem√°ticos:** Datos demogr√°ficos y econ√≥micos.\n",
    "- **Optimizaci√≥n log√≠stica:** Rutas de entrega y distribuci√≥n.\n",
    "\n",
    "### üåê Archivos HTML:\n",
    "\n",
    "- **Web scraping:** Extracci√≥n de datos estructurados de p√°ginas web.\n",
    "- **Construcci√≥n de datasets:** Recolecci√≥n de informaci√≥n de m√∫ltiples p√°ginas.\n",
    "- **An√°lisis de enlaces:** Estructura de redes y relaciones.\n",
    "- **Extracci√≥n de tablas:** Datos tabulares para an√°lisis estad√≠stico.\n",
    "- **Monitoreo de precios:** Rastrear precios en tiendas en l√≠nea.\n",
    "- **An√°lisis de tendencias:** Identificar temas populares en blogs y noticias.\n",
    "- **Automatizaci√≥n de reportes web:** Generar informes autom√°ticos.\n",
    "- **Reconocimiento de patrones visuales:** Detecci√≥n de banners y anuncios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPqUYnWUof7Eo4SjyQR8MFR",
   "mount_file_id": "11cBGjZ8uzuVbqHGETC0huHCGxFz0MEeR",
   "provenance": [
    {
     "file_id": "11cBGjZ8uzuVbqHGETC0huHCGxFz0MEeR",
     "timestamp": 1660679616179
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
